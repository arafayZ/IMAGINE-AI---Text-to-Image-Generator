import torch
from diffusers import StableDiffusionPipeline, StableDiffusionXLPipeline
import gradio as gr
import gc

# ---------- Function to clear RAM and GPU memory ----------
# This helps free memory after generating each image
def flush_memory():
    gc.collect()  # clear unused RAM
    if torch.cuda.is_available():
        torch.cuda.empty_cache()      # clear GPU cache
        torch.cuda.ipc_collect()      # clear GPU memory used by processes

# ---------- Select device ----------
# Use GPU if available, otherwise use CPU
device = "cuda" if torch.cuda.is_available() else "cpu"

# ---------- Model name ----------
model_id = "segmind/SSD-1B"

# ---------- Load the Stable Diffusion XL model ----------
# Use float16 for GPU (faster and less memory)
# Use float32 for CPU
pipe = StableDiffusionXLPipeline.from_pretrained(
    model_id,
    dtype=torch.float16 if device == "cuda" else torch.float32
).to(device)

# ---------- Enable memory-saving features ----------
pipe.enable_attention_slicing()  # reduces memory usage

# Enable xformers if GPU supports it (saves more memory)
if device == "cuda":
    try:
        pipe.enable_xformers_memory_efficient_attention()
    except Exception:
        pass  # ignore if not supported

# ---------- Negative prompt ----------
# These words tell the model what to avoid in the image
negative_prompt = (
    "blurry, low resolution, low quality, pixelated, distorted face, deformed hands, "
    "extra fingers, missing fingers, poor anatomy, bad proportions, mutated body, "
    "oversaturated colors, harsh lighting, noise, grainy, watermark, logo, text, signature"
)

# ---------- Image generation function ----------
# This function creates an image from the text prompt
def generate_image(prompt, height=512, width=512, steps=25, scale=7.5):
    image = pipe(
        prompt,
        height=height,                    # image height
        width=width,                      # image width
        num_inference_steps=steps,        # number of steps (higher = better quality)
        guidance_scale=scale,             # how closely image follows the prompt
        negative_prompt=negative_prompt   # things to avoid in image
    ).images[0]

    flush_memory()  # free memory after image is generated
    return image

# ---------- Gradio User Interface ----------
# This creates a simple web app
interface = gr.Interface(
    fn=generate_image,
    inputs=[
        gr.Textbox(lines=2, placeholder="Enter your prompt here..."),
        gr.Slider(minimum=256, maximum=768, step=64, value=512, label="Height"),
        gr.Slider(minimum=256, maximum=768, step=64, value=512, label="Width"),
        gr.Slider(minimum=5, maximum=50, step=1, value=25, label="Inference Steps"),
        gr.Slider(minimum=1, maximum=15, step=0.5, value=7.5, label="Guidance Scale"),
    ],
    outputs=gr.Image(type="pil"),
    title="IMAGINE AI - Text-to-Image Generator",
)

# ---------- Start the web app ----------
interface.launch(debug=True)
